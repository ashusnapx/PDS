{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: What is the difference between a t-test and a z-test? Provide an example scenario where you would use each type of test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between a t-test and a z-test lies in the assumptions about the population standard deviation and the sample size. Here's a brief overview:\n",
    "\n",
    "1. **Z-test**:\n",
    "   - Assumes that the population standard deviation (\\(\\sigma\\)) is known.\n",
    "   - Typically used when the sample size is large (usually \\(n \\geq 30\\)).\n",
    "   - The critical values are based on the standard normal distribution (z-distribution).\n",
    "\n",
    "**Example Scenario for Z-test**:\n",
    "Suppose a car manufacturer wants to test whether a new fuel additive increases the average fuel efficiency of their cars. They have access to a large dataset of fuel efficiency measurements. Since they have historical data on the population standard deviation of fuel efficiency, they can use a z-test to determine if the mean fuel efficiency with the new additive is significantly different from the historical average.\n",
    "\n",
    "2. **T-test**:\n",
    "   - Assumes that the population standard deviation (\\(\\sigma\\)) is unknown.\n",
    "   - Suitable for small sample sizes (typically used when \\(n < 30\\)) or when the population standard deviation is not known.\n",
    "   - The critical values are based on the t-distribution, which has heavier tails compared to the standard normal distribution.\n",
    "\n",
    "**Example Scenario for T-test**:\n",
    "Imagine a pharmaceutical company is conducting a clinical trial to test a new drug's effectiveness in reducing blood pressure. They select a relatively small group of participants (e.g., 20 individuals) and measure their blood pressure before and after taking the drug. Since the population standard deviation of the reduction in blood pressure is unknown and the sample size is small, the company would use a t-test to determine if the drug has a significant effect on reducing blood pressure.\n",
    "\n",
    "In summary, a z-test is used when you know the population standard deviation and have a large sample size, while a t-test is used when the population standard deviation is unknown or when dealing with small sample sizes. The choice between these tests depends on the specific characteristics of your data and the assumptions you can make about the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Q2: Differentiate between one-tailed and two-tailed tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Tailed Test**:\n",
    "\n",
    "In a one-tailed test (also known as a one-sided test), the hypothesis is tested against a specific direction or outcome. The critical region, where we would reject the null hypothesis, is located entirely on one side of the distribution (either the right or the left side). This type of test is used when we are interested in detecting an effect in a specific direction.\n",
    "\n",
    "**Example Scenario for One-Tailed Test**:\n",
    "Suppose a researcher is investigating whether a new drug can significantly increase a specific measurement, such as reaction time. The null hypothesis (\\(H_0\\)) might be that the drug has no effect on reaction time (\\(μ = 0\\)). The alternative hypothesis (\\(H_1\\)) would be that the drug decreases reaction time (\\(μ < 0\\)). Here, the researcher is interested in detecting a decrease in reaction time, so they use a one-tailed test with the critical region on the left side of the distribution.\n",
    "\n",
    "**Two-Tailed Test**:\n",
    "\n",
    "In a two-tailed test (also known as a two-sided test), the hypothesis is tested for any difference, regardless of the direction. The critical region is split into two parts, one on each side of the distribution. This type of test is used when we want to detect any significant deviation from the null hypothesis, whether it's an increase or a decrease.\n",
    "\n",
    "**Example Scenario for Two-Tailed Test**:\n",
    "Imagine a company is testing whether a new manufacturing process affects the average weight of their products. The null hypothesis (\\(H_0\\)) could be that the new process has no effect on weight (\\(μ = 0\\)). The alternative hypothesis (\\(H_1\\)) would be that there is a significant difference in weight due to the new process (\\(μ ≠ 0\\)). Here, the company wants to detect any significant difference, whether it's an increase or a decrease, so they use a two-tailed test.\n",
    "\n",
    "In summary, a one-tailed test is used when we have a specific direction or outcome in mind, and a two-tailed test is used when we are interested in detecting any significant deviation from the null hypothesis, regardless of the direction. The choice between these tests depends on the research question and the specific hypothesis being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Q3: Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type 1 Error (False Positive)**:\n",
    "\n",
    "A Type 1 error occurs when we incorrectly reject a true null hypothesis. In other words, we conclude that there is a significant effect when there is actually no effect in the population. This error is often denoted as \\(\\alpha\\) (alpha), which is the significance level of the test. It represents the probability of making a Type 1 error.\n",
    "\n",
    "**Example Scenario for Type 1 Error**:\n",
    "Let's say a company is testing a new security system for detecting intruders. The null hypothesis (\\(H_0\\)) is that the system is not effective at detecting intruders. The alternative hypothesis (\\(H_1\\)) is that the system is effective. If the company incorrectly rejects the null hypothesis (i.e., concludes that the system is effective) when, in reality, it's not, they have made a Type 1 error. This could lead to the unnecessary allocation of resources to a system that doesn't work.\n",
    "\n",
    "**Type 2 Error (False Negative)**:\n",
    "\n",
    "A Type 2 error occurs when we fail to reject a false null hypothesis. In other words, we conclude that there is no significant effect when there is actually an effect in the population. This error is often denoted as \\(\\beta\\) (beta). The power of a statistical test (1 - \\(\\beta\\)) is the probability of correctly rejecting a false null hypothesis. \n",
    "\n",
    "**Example Scenario for Type 2 Error**:\n",
    "Consider a medical test to detect a certain disease. The null hypothesis (\\(H_0\\)) is that the individual does not have the disease, while the alternative hypothesis (\\(H_1\\)) is that the individual has the disease. If the test fails to detect the disease in a person who actually has it, a Type 2 error has occurred. This could lead to a delay in diagnosis and treatment, potentially compromising the individual's health.\n",
    "\n",
    "In summary, Type 1 errors involve wrongly rejecting a true null hypothesis, and Type 2 errors involve failing to reject a false null hypothesis. Both types of errors are important considerations in hypothesis testing, and the balance between them depends on factors such as the chosen significance level, the power of the test, and the specific context of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Q4: Explain Bayes's theorem with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes's Theorem is a fundamental concept in probability theory that allows us to update our beliefs or probabilities about an event based on new evidence. It's named after the Reverend Thomas Bayes, who developed the theorem in the 18th century. The theorem is particularly useful in situations where we have prior knowledge (prior probability) about an event and then update that knowledge with new information (likelihood) to calculate a revised probability (posterior probability).\n",
    "\n",
    "The formula for Bayes's Theorem is:\n",
    "\n",
    "\\[ P(A|B) = \\frac{{P(B|A) \\cdot P(A)}}{{P(B)}} \\]\n",
    "\n",
    "Where:\n",
    "- \\(P(A|B)\\) is the posterior probability of event A given evidence B.\n",
    "- \\(P(B|A)\\) is the likelihood of evidence B given event A.\n",
    "- \\(P(A)\\) is the prior probability of event A.\n",
    "- \\(P(B)\\) is the probability of evidence B.\n",
    "\n",
    "**Example**:\n",
    "Let's consider a medical scenario where we want to determine the probability that a person has a certain disease given that they test positive on a diagnostic test. We'll use Bayes's Theorem to update our knowledge based on the test results.\n",
    "\n",
    "1. **Prior Probability (Prior Belief)**:\n",
    "   - The probability that a randomly chosen person has the disease before any test is \\(P(Disease) = 0.01\\) (1% of the population has the disease).\n",
    "\n",
    "2. **Likelihood (Test Accuracy)**:\n",
    "   - The probability that the test correctly detects the disease (true positive rate) is \\(P(Pos|Disease) = 0.95\\) (95% sensitivity).\n",
    "   - The probability that the test incorrectly indicates the disease when the person is healthy (false positive rate) is \\(P(Pos|No Disease) = 0.02\\) (2% false positive rate).\n",
    "\n",
    "3. **Evidence (Test Result)**:\n",
    "   - A person tests positive for the disease (Test Result: Positive).\n",
    "\n",
    "Now, we want to calculate the probability that the person actually has the disease given the positive test result, i.e., \\(P(Disease|Positive)\\).\n",
    "\n",
    "Using Bayes's Theorem:\n",
    "\\[ P(Disease|Positive) = \\frac{{P(Positive|Disease) \\cdot P(Disease)}}{{P(Positive)}} \\]\n",
    "\n",
    "We can now plug in the values:\n",
    "\\[ P(Disease|Positive) = \\frac{{P(Positive|Disease) \\cdot P(Disease)}}{{P(Positive|Disease) \\cdot P(Disease) + P(Positive|No Disease) \\cdot P(No Disease)}} \\]\n",
    "\n",
    "Substitute the known values:\n",
    "\\[ P(Disease|Positive) = \\frac{{0.95 \\cdot 0.01}}{{0.95 \\cdot 0.01 + 0.02 \\cdot 0.99}} \\]\n",
    "\n",
    "Solving this equation, we find the updated probability that the person has the disease given a positive test result. This shows how Bayes's Theorem combines our prior belief (prevalence of the disease) with the test's accuracy to provide a more accurate estimate of the probability that the person is truly affected by the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Q5: What is a confidence interval? How to calculate the confidence interval, explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
