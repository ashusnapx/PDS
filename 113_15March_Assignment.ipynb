{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explain with example : Artificial Intelligence, Machine learning, Deep learning and Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Artificial Intelligence (AI)**:\n",
    "   - **Explanation**: Artificial Intelligence refers to the simulation of human-like intelligence in machines, enabling them to perform tasks that typically require human intelligence, such as problem-solving, reasoning, learning, and decision-making.\n",
    "   - **Example**: Chatbots that can engage in natural language conversations, virtual assistants like Siri and Alexa, and autonomous vehicles that can navigate without human intervention.\n",
    "\n",
    "2. **Machine Learning (ML)**:\n",
    "   - **Explanation**: Machine Learning is a subset of AI that focuses on creating algorithms and models that allow computers to learn patterns from data and improve their performance over time without being explicitly programmed.\n",
    "   - **Example**: Email filtering that identifies spam based on patterns, recommendation systems used by Netflix to suggest movies, and fraud detection in financial transactions.\n",
    "\n",
    "3. **Deep Learning**:\n",
    "   - **Explanation**: Deep Learning is a specialized branch of machine learning that employs artificial neural networks to model and process complex patterns in data. It's inspired by the structure and function of the human brain's neural networks.\n",
    "   - **Example**: Image recognition systems that identify objects within images, voice recognition technology like Siri's ability to understand speech, and self-driving cars' ability to interpret and respond to their environment.\n",
    "\n",
    "4. **Data Science**:\n",
    "   - **Explanation**: Data Science involves using scientific methods, algorithms, processes, and systems to extract insights and knowledge from structured and unstructured data. It combines expertise in statistics, programming, domain knowledge, and data visualization.\n",
    "   - **Example**: Analyzing customer data to understand buying behaviors, predicting stock market trends using historical financial data, and using health records to identify patterns for disease prediction.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supervised learning? Examples, analogy, pros, cons, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning** is a type of machine learning where the algorithm learns from labeled training data, making predictions or decisions based on that learning. It involves providing the algorithm with input-output pairs, and the goal is to learn a mapping function that can predict the output for new, unseen inputs. Here's a breakdown of supervised learning:\n",
    "\n",
    "**Examples**:\n",
    "1. **Email Spam Detection**: Given a dataset of emails labeled as \"spam\" or \"not spam,\" a supervised learning algorithm learns to classify new emails as spam or not based on the patterns it identifies in the labeled data.\n",
    "2. **Medical Diagnosis**: Using a dataset of patient records labeled with specific medical conditions, an algorithm can predict whether a new patient has a certain condition based on their symptoms and medical history.\n",
    "\n",
    "**Analogy**: Think of a teacher guiding a student by providing correct answers (labels) for a set of questions (inputs). The student learns patterns and can answer new questions accurately.\n",
    "\n",
    "**Pros**:\n",
    "1. **Predictive Accuracy**: Supervised learning algorithms can achieve high accuracy in making predictions when provided with sufficient and relevant labeled data.\n",
    "2. **Interpretability**: The model's predictions can often be understood and explained, which is crucial for applications like medicine and law.\n",
    "3. **Widespread Use**: Supervised learning is widely applicable across various domains and has led to breakthroughs in areas like image recognition, natural language processing, and more.\n",
    "\n",
    "**Cons**:\n",
    "1. **Dependency on Labeled Data**: Supervised learning requires a large amount of accurately labeled data for training, which can be time-consuming and expensive to collect.\n",
    "2. **Limited to Known Patterns**: The algorithm can only make predictions based on patterns present in the training data. If the data doesn't represent all possible scenarios, the model may fail in new situations.\n",
    "3. **Overfitting**: If the model becomes too complex or is trained on noise in the data, it may perform well on the training data but poorly on new, unseen data.\n",
    "\n",
    "**Use Case Analogy**: Imagine you're teaching a computer to differentiate between different types of fruit by showing it labeled pictures of apples and oranges. The computer learns the features that distinguish each fruit, and when presented with a new picture, it can classify it as an apple or an orange based on what it learned.\n",
    "\n",
    "In summary, supervised learning is a foundational concept in machine learning where the algorithm learns from labeled data to make predictions or classifications. It's powerful for a wide range of tasks but relies heavily on quality labeled data and can be limited by its dependence on known patterns.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised learning? Examples, analogy, pros, cons, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised Learning** is a type of machine learning where the algorithm learns from unlabeled data, finding patterns and structures within the data without explicit guidance in the form of labeled outputs. Here's an overview of unsupervised learning:\n",
    "\n",
    "**Examples**:\n",
    "1. **Clustering**: Grouping similar data points together based on their features. An algorithm might cluster customer data to identify segments for targeted marketing.\n",
    "2. **Dimensionality Reduction**: Reducing the number of features while retaining important information. Principal Component Analysis (PCA) is used to simplify data for visualization or processing.\n",
    "3. **Anomaly Detection**: Identifying unusual patterns that don't conform to the norm. This is used for fraud detection, network security, and more.\n",
    "\n",
    "**Analogy**: Think of an explorer entering a new land without a map or any labels. The explorer's task is to discover hidden patterns in the landscape and group similar features together.\n",
    "\n",
    "**Pros**:\n",
    "1. **Pattern Discovery**: Unsupervised learning can reveal hidden patterns in data that may not be apparent through manual analysis.\n",
    "2. **Scalability**: Unsupervised learning techniques can be applied to large datasets without the need for labeled data.\n",
    "3. **New Insights**: Unsupervised learning can lead to new insights and discoveries that may not have been considered by humans.\n",
    "\n",
    "**Cons**:\n",
    "1. **Lack of Supervision**: Without labeled data, it's challenging to evaluate the accuracy or quality of the discovered patterns.\n",
    "2. **Subjective Interpretation**: The patterns uncovered might be open to interpretation, and the choice of algorithm and parameters can significantly affect results.\n",
    "3. **Complexity**: Some unsupervised learning tasks, like clustering, can be complex and may require careful consideration of parameters and algorithms.\n",
    "\n",
    "**Use Case Analogy**: Imagine you have a bag of mixed puzzle pieces, and you want to organize them into groups that fit together. You don't have a picture of the complete puzzle, but you notice similarities in colors and shapes to group the pieces.\n",
    "\n",
    "In summary, unsupervised learning is about extracting insights and structure from unlabeled data. It's beneficial for tasks where patterns aren't known beforehand and can lead to new discoveries. However, it requires careful interpretation and can be more challenging to evaluate compared to supervised learning.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Semi-supervised learning? Examples, analogy, pros, cons, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semi-Supervised Learning** is a hybrid approach that combines elements of both supervised and unsupervised learning. It involves using a small amount of labeled data along with a larger amount of unlabeled data to improve the performance of machine learning models. Here's an overview of semi-supervised learning:\n",
    "\n",
    "**Examples**:\n",
    "1. **Text Classification**: You have a large amount of text data but only a small portion is labeled. Semi-supervised learning can use the labeled data to guide the clustering of the unlabeled text data.\n",
    "2. **Image Segmentation**: You have labeled images with objects of interest, and a larger set of unlabeled images. The labeled images can help guide the identification of similar objects in the unlabeled images.\n",
    "\n",
    "**Analogy**: Consider a student who is learning to identify different species of birds. They are provided with a few labeled pictures of birds and many unlabeled pictures. By using the labeled pictures as a guide, the student can learn to recognize patterns and identify bird species in the unlabeled pictures.\n",
    "\n",
    "**Pros**:\n",
    "1. **Leveraging Limited Labels**: Semi-supervised learning can make efficient use of limited labeled data to improve model performance.\n",
    "2. **Generalization**: By incorporating both labeled and unlabeled data, models can potentially generalize better to new, unseen data.\n",
    "3. **Cost Savings**: Collecting labeled data can be expensive and time-consuming. Semi-supervised learning reduces the dependence on a large amount of labeled data.\n",
    "\n",
    "**Cons**:\n",
    "1. **Complexity**: Semi-supervised learning requires managing both labeled and unlabeled data, as well as addressing the challenges that come with each type.\n",
    "2. **Quality of Labels**: The performance of semi-supervised learning heavily relies on the quality and representativeness of the labeled data.\n",
    "3. **Algorithm Selection**: Choosing the right combination of supervised and unsupervised techniques can be challenging and depends on the specific problem.\n",
    "\n",
    "**Use Case Analogy**: Imagine you're assembling a jigsaw puzzle, and you have some pieces that are clearly part of the border (labeled) and many pieces that are still scattered (unlabeled). By first identifying the border pieces, you can use them as a guide to start connecting the rest of the puzzle.\n",
    "\n",
    "In summary, semi-supervised learning aims to bridge the gap between supervised and unsupervised learning by using both labeled and unlabeled data. It offers benefits such as leveraging limited labeled data and generalization, but also comes with challenges in terms of complexity and algorithm selection.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reinforcement learning? Examples, analogy, pros, cons, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement Learning** is a type of machine learning in which an agent learns how to interact with an environment to maximize a reward signal. It's inspired by the way humans learn through trial and error. Here's an overview of reinforcement learning:\n",
    "\n",
    "**Examples**:\n",
    "1. **Game Playing**: Training an AI to play games like chess or Go, where the AI learns from its moves and their outcomes to improve its strategy over time.\n",
    "2. **Robotics**: Teaching a robot to perform tasks like walking or picking up objects by providing rewards for successful actions and penalties for failures.\n",
    "3. **Autonomous Driving**: Training self-driving cars to navigate roads and make decisions based on real-time feedback from the environment.\n",
    "\n",
    "**Analogy**: Imagine training a dog to perform tricks. When the dog performs a trick correctly, it receives a treat (reward), which encourages it to repeat the behavior. Over time, the dog learns to associate certain actions with positive outcomes.\n",
    "\n",
    "**Pros**:\n",
    "1. **Learning Through Interaction**: Reinforcement learning agents learn by actively interacting with their environment, making it suitable for tasks where direct guidance is challenging.\n",
    "2. **Complex Decision Making**: Reinforcement learning can handle complex decision-making scenarios where the best action may not be immediately obvious.\n",
    "3. **Adaptability**: Agents can adapt to changing environments and learn optimal strategies for different scenarios.\n",
    "\n",
    "**Cons**:\n",
    "1. **Exploration vs. Exploitation**: Balancing exploration (trying new actions to learn) and exploitation (using learned actions for rewards) can be challenging.\n",
    "2. **Delayed Rewards**: In some cases, rewards may be delayed, making it difficult for the agent to connect actions with their long-term outcomes.\n",
    "3. **Sample Inefficiency**: Reinforcement learning can require a large number of interactions with the environment to learn effective policies.\n",
    "\n",
    "**Use Case Analogy**: Consider teaching a virtual character in a video game to navigate a maze and find a treasure. The character must explore different paths, learn from its mistakes (falling into traps), and improve its strategy over time to reach the treasure faster.\n",
    "\n",
    "In summary, reinforcement learning is about training agents to make sequential decisions by maximizing rewards. It's suitable for tasks involving interaction with an environment, but it requires careful balancing of exploration and exploitation. While it can handle complex decision-making, it also faces challenges like delayed rewards and sample inefficiency.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4- What is the difference between AI, ML, DL, and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key differences between Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Data Science (DS) using essential characteristics:\n",
    "\n",
    "| Characteristic          | Artificial Intelligence (AI)         | Machine Learning (ML)           | Deep Learning (DL)               | Data Science (DS)                |\n",
    "|-------------------------|-------------------------------------|---------------------------------|----------------------------------|----------------------------------|\n",
    "| Focus                   | Imitating human intelligence        | Developing algorithms           | Neural networks and architectures| Extracting insights from data    |\n",
    "| Application Scope       | Broad applications                  | Generalized problem-solving     | Pattern recognition and analysis | Multidisciplinary applications   |\n",
    "| Approach                | Rule-based and heuristic            | Learning from data patterns     | Hierarchical feature learning    | Data-driven and analytical      |\n",
    "| Human Intervention      | High, initially                      | Moderate                         | Low, automating feature learning | Moderate                         |\n",
    "| Examples                | Chatbots, game playing, robotics     | Predictive modeling, clustering| Image and speech recognition     | Predictive analytics, visualization|\n",
    "| Complexity              | Can be complex and rule-intensive  | Based on algorithms             | Involves complex architectures   | Varies depending on the project |\n",
    "| Learning Paradigm       | Rule-based, logical inference       | Learning from labeled data      | Hierarchical feature abstraction | Utilizes statistical methods    |\n",
    "| Data Dependency         | Can be less data-dependent          | Requires labeled training data  | Requires large labeled datasets  | Involves diverse datasets       |\n",
    "| Feature Engineering     | Relies on explicit feature design   | Partially automates feature extraction| Automates feature extraction| Focuses on data preprocessing  |\n",
    "| Depth of Learning       | Varies widely                       | Moderate depth in some algorithms| Deep layers of neural networks   | Depends on analysis complexity  |\n",
    "| Computational Intensity | Depends on tasks and algorithms     | Moderate                         | High, requires significant power | Moderate to high                |\n",
    "| Real-time Applications  | Can vary, may be slower             | Real-time inference is possible | Real-time applications possible  | Depends on data and analysis    |\n",
    "| Ethics and Bias         | Can raise ethical concerns          | Can propagate biases            | Can propagate biases             | Requires ethical considerations  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# What is the difference between supervised, unsupervised, semi-supervised and reinforcement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Key differences between Supervised Learning, Unsupervised Learning, Semi-Supervised Learning, and Reinforcement Learning using essential characteristics:***\n",
    "\n",
    "| Characteristic              | Supervised Learning                     | Unsupervised Learning                 | Semi-Supervised Learning              | Reinforcement Learning                |\n",
    "|-----------------------------|-----------------------------------------|---------------------------------------|---------------------------------------|---------------------------------------|\n",
    "| Learning Paradigm           | Requires labeled data for training       | Doesn't require labeled data         | Utilizes both labeled and unlabeled data| Learns from interactions with an environment|\n",
    "| Goal                        | Predict outcomes based on input data     | Discover patterns and structures     | Enhance learning with limited labels  | Learn optimal actions for rewards     |\n",
    "| Examples                    | Classification, regression              | Clustering, dimensionality reduction | Combining labeled and unlabeled tasks | Game playing, robotics, optimization  |\n",
    "| Data Dependency             | Depends on labeled data availability     | No dependency on labeled data        | Uses available labeled and unlabeled data| Limited labeled data, exploration     |\n",
    "| Feature Engineering         | Explicit feature engineering required   | Minimal or no feature engineering    | Can leverage unlabeled data for features| Limited feature engineering           |\n",
    "| Human Intervention          | High involvement initially              | Limited involvement                 | Can utilize unlabeled data for labeling| Interaction-based learning            |\n",
    "| Real-time Learning          | Depends on model complexity and data     | Real-time learning is not common     | Depends on data availability          | Real-time adaptation and decision-making|\n",
    "| Bias and Fairness           | Can propagate biases in labeled data     | Bias can arise in unlabeled data     | Biases can impact labeled and unlabeled| Can lead to biased learning           |\n",
    "| Interpretability           | Can provide insights into decision-making| Complex structures may be harder to interpret| Mix of labeled and unlabeled data may enhance insights| Can be challenging to interpret       |\n",
    "| Use Cases                   | Medical diagnosis, image classification | Customer segmentation, anomaly detection | Fraud detection, sentiment analysis | Game playing, robotics, optimization  |\n",
    "| Learning Approach          | Learning from labeled data patterns     | Learning from data patterns         | Enhancing learning with more data     | Learning from trial and error         |\n",
    "| Complexity                  | Can handle complex relationships        | Can discover hidden relationships   | Utilizes a mix of supervised and unsupervised learning| Balancing exploration and exploitation|\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train, test, validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key differences between Training Set, Test Set, and Validation Set along with their importance:**\n",
    "\n",
    "| Characteristic       | Training Set                  | Test Set                   | Validation Set             |\n",
    "|----------------------|-------------------------------|----------------------------|----------------------------|\n",
    "| Purpose              | Used to train the model       | Used to evaluate performance| Used to fine-tune and select the best model |\n",
    "| Importance           | Crucial for model learning     | Assess generalization      | Tune hyperparameters, prevent overfitting |\n",
    "| Data Split           | Largest portion of the data   | Reserved for evaluation    | Small portion of the data  |\n",
    "| Model Impact         | Directly influences model     | Independent assessment     | Prevents overfitting, aids selection of best model |\n",
    "| Data Overlap         | No overlap with test/validate | No overlap with training   | No overlap with training/test sets |\n",
    "| Generalization       | Learning patterns from data   | Assessing unseen data      | Choosing best model, generalize better |\n",
    "| Hyperparameter Tuning| Not used for tuning           | Not used for tuning        | Used for tuning hyperparameters |\n",
    "| Model Selection      | Not used for selecting model | Not used for selecting model| Helps select best model    |\n",
    "| Data Diversity       | Used to learn model           | Indicates model's generalization| Used for fine-tuning, selection of best model |\n",
    "| Sample Size          | Larger sample size            | Represents real-world data  | Smaller sample size        |\n",
    "| Risk of Overfitting  | Lower risk                    | No risk                    | Prevents overfitting       |\n",
    "| Impact on Learning   | Primary data for learning     | Secondary evaluation data  | Enhances model performance |\n",
    "| End Goal             | Improving model performance   | Ensuring unbiased evaluation| Selecting the best model   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 7. Explain how unsupervised learning can be used in anomaly detection? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning in Anomaly Detection:\n",
    "\n",
    "Unsupervised learning is particularly useful in anomaly detection scenarios where there are limited or no labeled anomalies available for training. Anomaly detection aims to identify instances that significantly deviate from the normal behavior of a dataset. Unsupervised learning techniques excel at identifying such anomalies by learning the inherent structure of the data without relying on labeled anomalies.\n",
    "\n",
    "### How it Works:\n",
    "\n",
    "1. **Representation Learning**: Unsupervised algorithms learn the underlying patterns and structures in the data by identifying clusters, distributions, or relationships among data points.\n",
    "\n",
    "2. **Normal Behavior Modeling**: These algorithms create a model of the \"normal\" behavior of the data. Instances that deviate significantly from this model are considered anomalies.\n",
    "\n",
    "3. **Threshold Setting**: A threshold is set to distinguish between normal and anomalous instances. Any data point that falls beyond this threshold is flagged as an anomaly.\n",
    "\n",
    "4. **Anomaly Detection**: The model is then used to detect instances that differ from the expected normal behavior.\n",
    "\n",
    "### Use Cases of Unsupervised Learning:\n",
    "\n",
    "1. **Credit Card Fraud Detection**: Unsupervised learning can identify unusual spending patterns that may indicate fraudulent credit card transactions. Anomalies could be transactions with high amounts or occurring in unexpected locations.\n",
    "\n",
    "2. **Network Intrusion Detection**: Identifying unusual patterns in network traffic helps detect potential cyberattacks. Unsupervised algorithms can spot abnormal data packets or traffic spikes.\n",
    "\n",
    "3. **Manufacturing Defects**: In manufacturing, unsupervised learning can detect faulty products by analyzing sensor data. Deviations in the sensor readings can indicate defects.\n",
    "\n",
    "4. **Healthcare Anomaly Detection**: Unsupervised learning can help identify unusual patient behavior in healthcare settings, like detecting anomalies in vital sign readings.\n",
    "\n",
    "5. **Financial Market Anomalies**: Detecting abnormal market behavior or sudden price changes in financial markets can assist traders in making informed decisions.\n",
    "\n",
    "6. **Customer Segmentation**: Unsupervised clustering techniques can segment customers based on their behavior, helping businesses tailor marketing strategies.\n",
    "\n",
    "7. **Image and Video Analysis**: Unsupervised techniques can be used for anomaly detection in image and video data, such as identifying defective products on an assembly line.\n",
    "\n",
    "8. **Natural Language Processing**: Detecting unusual patterns in textual data can help identify fake reviews or spam emails.\n",
    "\n",
    "9. **Environmental Monitoring**: Unsupervised learning can identify unusual environmental conditions by analyzing sensor data in applications like weather forecasting.\n",
    "\n",
    "10. **Genomics and Bioinformatics**: Unsupervised learning techniques can assist in identifying anomalies in gene expression data for disease diagnosis.\n",
    "\n",
    "Unsupervised learning methods, such as clustering, density estimation, and dimensionality reduction, are highly versatile and can be adapted to various anomaly detection scenarios without requiring labeled data. They are especially useful when anomalies are rare and poorly defined, making them a powerful tool for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Q8- List down some commonly used supervised learning algorithms and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List of commonly used algorithms in supervised, unsupervised, semi-supervised, and reinforcement learning along with brief explanations and how they address the limitations of previous algorithms.*\n",
    "\n",
    "| Algorithm Type     | Common Algorithms  | Explanation & Advantages |\n",
    "|--------------------|--------------------|--------------------------|\n",
    "| Supervised Learning| Linear Regression, Decision Trees, Random Forests | Linear Regression predicts continuous outputs, Decision Trees capture non-linear relationships, Random Forests reduce overfitting by combining multiple trees. |\n",
    "|                    | Support Vector Machines (SVM), K-Nearest Neighbors (KNN) | SVM finds optimal hyperplanes, KNN classifies based on nearest neighbors. |\n",
    "|                    | Neural Networks, Gradient Boosting | Neural Networks model complex patterns, Gradient Boosting improves prediction accuracy. |\n",
    "| Unsupervised Learning | K-Means Clustering, Hierarchical Clustering | K-Means groups data into clusters, Hierarchical Clustering forms nested clusters. |\n",
    "|                    | Principal Component Analysis (PCA), t-SNE | PCA reduces dimensionality, t-SNE visualizes high-dimensional data in lower dimensions. |\n",
    "|                    | Gaussian Mixture Models (GMM), DBSCAN | GMM models data as a combination of Gaussian distributions, DBSCAN identifies clusters of varying shapes and sizes. |\n",
    "| Semi-Supervised Learning | Self-Training, Co-Training | Self-Training iteratively labels unlabeled data using model predictions, Co-Training uses multiple views of data to improve labeling. |\n",
    "|                    | Multi-View Learning, Transductive SVM | Multi-View Learning combines information from different data views, Transductive SVM leverages unlabeled data for decision boundary improvement. |\n",
    "| Reinforcement Learning | Q-Learning, Deep Q-Networks (DQN) | Q-Learning learns action-value pairs, DQN uses neural networks to improve Q-Learning stability. |\n",
    "|                    | Policy Gradient Methods, Actor-Critic | Policy Gradient Methods optimize action policies directly, Actor-Critic combines policy learning and value learning. |\n",
    "|                    | Proximal Policy Optimization (PPO), Deep Deterministic Policy Gradients (DDPG) | PPO optimizes policy while ensuring stability, DDPG extends policy gradients to continuous action spaces. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
